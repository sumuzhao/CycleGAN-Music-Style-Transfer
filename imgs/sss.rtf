{\rtf1\ansi\ansicpg1252\cocoartf1561\cocoasubrtf600
{\fonttbl\f0\fswiss\fcharset0 Helvetica;}
{\colortbl;\red255\green255\blue255;}
{\*\expandedcolortbl;;}
\paperw11900\paperh16840\margl1440\margr1440\vieww10800\viewh8400\viewkind0
\pard\tx566\tx1133\tx1700\tx2267\tx2834\tx3401\tx3968\tx4535\tx5102\tx5669\tx6236\tx6803\pardirnatural\partightenfactor0

\f0\fs24 \cf0 ## Prerequisites\
- tensorflow r1.2\
- numpy 1.11.0\
- scipy 0.17.0\
- pillow 3.3.0\
\
## Getting Started\
### Installation\
- Install tensorflow from https://github.com/tensorflow/tensorflow\
- Clone this repo:\
```bash\
git clone https://github.com/xhujoy/CycleGAN-tensorflow\
cd CycleGAN-tensorflow\
```\
\
### Train\
- Download a dataset (e.g. zebra and horse images from ImageNet):\
```bash\
bash ./download_dataset.sh horse2zebra\
```\
- Train a model:\
```bash\
CUDA_VISIBLE_DEVICES=0 python main.py --dataset_dir=horse2zebra\
```\
- Use tensorboard to visualize the training details:\
```bash\
tensorboard --logdir=./logs\
```\
\
### Test\
- Finally, test the model:\
```bash\
CUDA_VISIBLE_DEVICES=0 python main.py --dataset_dir=horse2zebra --phase=test --which_direction=AtoB\
```\
\
## Training and Test Details\
To train a model,  \
```bash\
CUDA_VISIBLE_DEVICES=0 python main.py --dataset_dir=/path/to/data/ \
```\
Models are saved to `./checkpoints/` (can be changed by passing `--checkpoint_dir=your_dir`).  \
\
To test the model,\
```bash\
CUDA_VISIBLE_DEVICES=0 python main.py --dataset_dir=/path/to/data/ --phase=test --which_direction=AtoB/BtoA\
```\
\
## Datasets\
Download the datasets using the following script:\
```bash\
bash ./download_dataset.sh dataset_name\
```\
- `facades`: 400 images from the [CMP Facades dataset](http://cmp.felk.cvut.cz/~tylecr1/facade/).\
- `cityscapes`: 2975 images from the [Cityscapes training set](https://www.cityscapes-dataset.com/).\
- `maps`: 1096 training images scraped from Google Maps.\
- `horse2zebra`: 939 horse images and 1177 zebra images downloaded from [ImageNet](http://www.image-net.org/) using keywords `wild horse` and `zebra`.\
- `apple2orange`: 996 apple images and 1020 orange images downloaded from [ImageNet](http://www.image-net.org/) using keywords `apple` and `navel orange`.\
- `summer2winter_yosemite`: 1273 summer Yosemite images and 854 winter Yosemite images were downloaded using Flickr API. See more details in our paper.\
- `monet2photo`, `vangogh2photo`, `ukiyoe2photo`, `cezanne2photo`: The art images were downloaded from [Wikiart](https://www.wikiart.org/). The real photos are downloaded from Flickr using combination of tags *landscape* and *landscapephotography*. The training set size of each class is Monet:1074, Cezanne:584, Van Gogh:401, Ukiyo-e:1433, Photographs:6853.\
- `iphone2dslr_flower`: both classe of images were downlaoded from Flickr. The training set size of each class is iPhone:1813, DSLR:3316. See more details in our paper.\
\
\
## Reference\
- The torch implementation of CycleGAN, https://github.com/junyanz/CycleGAN\
- The tensorflow implementation of pix2pix, https://github.com/yenchenlin/pix2pix-tensorflow}